# EcoSort - AI-Powered Recycling Classifier

ğŸ¯ An intelligent waste classification system that automatically identifies and categorizes recyclable materials using computer vision and YOLOv11.

![EcoSort Demo](https://img.shields.io/badge/Status-Production-green)
![Next.js](https://img.shields.io/badge/Next.js-16-black)
![Django](https://img.shields.io/badge/Django-4.2-green)
![YOLO](https://img.shields.io/badge/YOLO-v11n-blue)

## âœ¨ Features

- ğŸ¯ **Real-time Classification** - Instant waste categorization using YOLOv11n model
- ğŸ“¸ **Multiple Input Methods** - Drag-drop, file upload, or camera capture
- ğŸ¨ **Interactive UI** - 3D-style conveyor belt with smooth animations
- ğŸ“Š **Performance Metrics** - Detailed model statistics and analytics
- ğŸ”„ **Live Tracking** - Watch items get sorted in real-time
- ğŸŒ™ **Dark Mode** - Beautiful UI with dark theme support

## ğŸš€ Quick Start

### Prerequisites
- Node.js v18+
- Python 3.9+
- pnpm or npm

### Backend Setup
```bash
cd eco-backend
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
python manage.py migrate
python manage.py runserver
```

### Frontend Setup
```bash
pnpm install
echo "NEXT_PUBLIC_BACKEND_URL=http://127.0.0.1:8000" > .env.local
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸ“š Documentation

**ğŸŒ Interactive Documentation**: Visit [/docs](http://localhost:3000/docs) when running locally, or [https://ecopro.hamzaihsan.me/docs](https://ecopro.hamzaihsan.me/docs) for the live demo.

**ğŸ“– Complete Technical Docs**: See [FULL_DOCUMENTATION.md](./FULL_DOCUMENTATION.md) for detailed technical documentation.

The `/docs` page includes:
- Step-by-step setup guide
- System architecture overview
- API reference with examples
- Component explanations
- Testing instructions
- Deployment guides
- Troubleshooting tips

## ğŸ—‘ï¸ Supported Categories

| Category    | Icon | Description         |
|-------------|------|---------------------|
| Paper       | ğŸ“„   | Paper products      |
| Cardboard   | ğŸ“¦   | Cardboard boxes     |
| Plastic     | ğŸ¥¤   | Plastic containers  |
| Vegetation  | ğŸŒ¿   | Plant matter        |
| Biological  | ğŸ‚   | Organic waste       |
| Metal       | ğŸ”©   | Metal items         |
| Clothes     | ğŸ‘•   | Textiles/fabric     |
| Glass       | ğŸ¾   | Glass bottles/jars  |
| Trash       | ğŸ—‘ï¸   | General waste       |
| Shoes       | ğŸ‘Ÿ   | Footwear            |
| Battery     | ğŸ”‹   | Batteries           |

## ğŸ—ï¸ Tech Stack

**Frontend:**
- Next.js 16 (App Router)
- React 19
- TypeScript
- Tailwind CSS v4
- shadcn/ui components

**Backend:**
- Django 4.2
- Django REST Framework
- Ultralytics YOLOv11n
- Python 3.x

**Deployment:**
- Frontend: Vercel
- Backend: Render
- Model: YOLOv11n (12 classes)

## ğŸ§ª Testing

```bash
# Test backend API
curl http://127.0.0.1:8000/api/models/

# Test classification
curl -X POST http://127.0.0.1:8000/api/classify/ -F "image=@test.jpg"

# Run frontend
pnpm dev
```

## ğŸ§¬ Training & Experimentation

To reproduce or modify the model training:

```bash
# 1. Install Jupyter
pip install jupyter notebook ultralytics

# 2. Navigate to training directory
cd "Yolo medium 3 classes"

# 3. Launch Jupyter notebook
jupyter notebook TestingF.ipynb

# 4. The notebook includes:
#    - Model loading and evaluation
#    - Confusion matrix generation
#    - Performance metrics calculation
#    - Result visualization
```

**Training Results** (3-class model):
- Precision: 74.38%
- Recall: 71.38%
- F1 Score: 72.85%
- Specificity: 90.93%

## ğŸ“Š Model & Dataset Information

### Model
- **Model**: YOLOv11n (nano variant)
- **Task**: Image Classification
- **Classes**: 12 waste categories
- **Parameters**: ~2.6M
- **Input**: 224x224 RGB images
- **Output**: Top-5 predictions with confidence scores
- **Inference**: ~50-200ms (CPU)

### Dataset
- **Total Images**: ~19,949 labeled images
- **Categories**: 12 waste types
- **Distribution**: Ranges from 436 (Vegetation) to 5,325 (Clothes) images per class
- **Training Notebook**: `Yolo medium 3 classes/TestingF.ipynb`
- **Augmentation**: Rotation, flip, color jittering, crop/resize

**Dataset Structure**:
```
Dataset/
â”œâ”€â”€ battery/               (945 images)
â”œâ”€â”€ biological/            (1,396 images)
â”œâ”€â”€ clothes/               (5,325 images)
â”œâ”€â”€ metal/                 (1,559 images)
â”œâ”€â”€ paper/                 (1,550 images)
â”œâ”€â”€ shoes/                 (1,977 images)
â”œâ”€â”€ trash/                 (697 images)
â”œâ”€â”€ Vegetation/            (436 images)
â”œâ”€â”€ Miscellaneous Trash/   (495 images)
â””â”€â”€ Dataset/               (3-class subset)
    â”œâ”€â”€ cardboard/         (1,352 images)
    â”œâ”€â”€ glass/             (2,431 images)
    â””â”€â”€ plastic/           (1,786 images)
```

View detailed performance metrics at [/stats](http://localhost:3000/stats)

## ğŸš€ Deployment

### Backend (Render)
```bash
# Build
cd eco-backend && pip install -r requirements.txt && python manage.py collectstatic --noinput

# Start
cd eco-backend && gunicorn config.wsgi:application --bind 0.0.0.0:$PORT
```

### Frontend (Vercel)
Automatically deployed on push to main branch.

Environment variable required:
```
NEXT_PUBLIC_BACKEND_URL=https://your-backend.onrender.com
```

## ğŸ“ Project Structure

```
eco-pro/
â”œâ”€â”€ app/                    # Next.js App Router
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”œâ”€â”€ docs/              # Documentation page
â”‚   â”œâ”€â”€ stats/             # Statistics page
â”‚   â””â”€â”€ page.tsx           # Home page
â”œâ”€â”€ components/            # React components
â”œâ”€â”€ Dataset/               # Training dataset (~20K images)
â”‚   â”œâ”€â”€ battery/           # Battery images
â”‚   â”œâ”€â”€ biological/        # Organic waste images
â”‚   â”œâ”€â”€ clothes/           # Textile images
â”‚   â”œâ”€â”€ metal/             # Metal items
â”‚   â”œâ”€â”€ paper/             # Paper products
â”‚   â”œâ”€â”€ shoes/             # Footwear
â”‚   â”œâ”€â”€ trash/             # General waste
â”‚   â”œâ”€â”€ Vegetation/        # Plant matter
â”‚   â”œâ”€â”€ Miscellaneous Trash/
â”‚   â””â”€â”€ Dataset/           # 3-class subset
â”‚       â”œâ”€â”€ cardboard/
â”‚       â”œâ”€â”€ glass/
â”‚       â””â”€â”€ plastic/
â”œâ”€â”€ Yolo medium 3 classes/ # Training resources
â”‚   â”œâ”€â”€ TestingF.ipynb     # Training notebook
â”‚   â”œâ”€â”€ best.pt            # YOLOv11m model (20MB)
â”‚   â””â”€â”€ confusion_matrix*.png
â”œâ”€â”€ eco-backend/           # Django backend
â”‚   â”œâ”€â”€ classifier/        # Main app
â”‚   â”œâ”€â”€ config/            # Settings
â”‚   â””â”€â”€ yoloMODEL_old_cls_12.pt
â”œâ”€â”€ lib/                   # Utilities
â””â”€â”€ public/                # Static assets
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

MIT License - feel free to use this project for learning or production.

## ğŸ™ Credits

- **YOLO**: [Ultralytics](https://github.com/ultralytics/ultralytics)
- **UI Components**: [shadcn/ui](https://ui.shadcn.com/)
- **Icons**: [Lucide React](https://lucide.dev/)
- **Framework**: [Next.js](https://nextjs.org/) & [Django](https://www.djangoproject.com/)

## ğŸ”— Links

- **Live Demo**: [https://ecopro.hamzaihsan.me](https://ecopro.hamzaihsan.me)
- **Documentation**: [/docs](https://ecopro.hamzaihsan.me/docs)
- **Statistics**: [/stats](https://ecopro.hamzaihsan.me/stats)

---

Built with â¤ï¸ using Next.js and Django
